{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь только импорт\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import math\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as web\n",
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Process\n",
    "from joblib import Parallel, delayed, wrap_non_picklable_objects\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from joblib import parallel_backend\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import operator\n",
    "import csv\n",
    "from fake_useragent import UserAgent\n",
    "import requests, json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем список тикеров, торгуемых на СПб бирже\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1720"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Собираем список тикеров, торгуемых на СПб бирже')\n",
    "\n",
    "dataset = pd.read_csv('ListingSecurityList.csv', sep = ';')\n",
    "dataset = dataset[['s_RTS_code', 'e_full_name']]\n",
    "tickers_only = dataset['s_RTS_code'].values\n",
    "\n",
    "len(tickers_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_web_data(j):\n",
    "\n",
    "    try:\n",
    "        tickerSymbol = tickers_only[j]\n",
    "        tickerData = yf.Ticker(tickerSymbol)\n",
    "        ticker_info = tickerData.info\n",
    "        marketCap = ticker_info['marketCap']\n",
    "        P_E = ticker_info['forwardPE']\n",
    "        price = ticker_info['currentPrice']\n",
    "    except:\n",
    "        marketCap = 0\n",
    "        P_E = 0\n",
    "        price = 0\n",
    "    dataset.loc[j, 'marketCap'] = marketCap\n",
    "    dataset.loc[j, 'price'] = price\n",
    "    dataset.loc[j, 'P/E'] = P_E\n",
    "    \n",
    "    try:\n",
    "        ROE = ticker_info['returnOnEquity']\n",
    "    except:\n",
    "        ROE = 0\n",
    "    dataset.loc[j, 'ROE'] = ROE\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        table=pd.read_html('https://www.macrotrends.net/stocks/charts/' + tickers_only[j] + '/' + tickers_only[j] + '/net-income')\n",
    "        rg_table = table[1]\n",
    "        rg_table = rg_table.iloc[:, 1].values\n",
    "        rg_table = filter(lambda v: v==v, rg_table)\n",
    "        rg_table = [s.replace('$', '') for s in rg_table]\n",
    "        rg_table = [s.replace(',', '') for s in rg_table]\n",
    "        x = np.asarray(rg_table, dtype=np.float64)\n",
    "        x_rev = np.flip(x)\n",
    "        x_rev = x_rev[-21:]\n",
    "\n",
    "        ttm_list = list()\n",
    "        for i in range(len(x_rev)-3):\n",
    "            ttm = x_rev[i] + x_rev[i+1] + x_rev[i+2] + x_rev[i+3]\n",
    "            ttm_list.append(ttm)\n",
    "\n",
    "        X = np.linspace(1, len(ttm_list), num=len(ttm_list))\n",
    "        X = X.reshape(-1, 1)\n",
    "        \n",
    "        reg = LinearRegression().fit(X, ttm_list)\n",
    "        determination = round(reg.score(X, ttm_list), 2)\n",
    "        \n",
    "        if (ttm_list[-1] < 100) or (ttm_list[0] < 100):\n",
    "            growth = 0\n",
    "        else:\n",
    "            growth = round(((ttm_list[-1] / ttm_list[0])**(1/((len(x_rev)-1)/4)) - 1) * 100, 2)\n",
    "    \n",
    "        \n",
    "       \n",
    "    except:\n",
    "        growth = 0\n",
    "        determination = 0\n",
    "    dataset.loc[j, 'growth'] = growth\n",
    "    dataset.loc[j, 'determination'] = determination\n",
    "    \n",
    "      \n",
    "    \n",
    "    try:\n",
    "        table=pd.read_html('https://www.macrotrends.net/stocks/charts/' + tickers_only[j] + '/' + tickers_only[j] + '/net-profit-margin')\n",
    "        net_margin_mean = 0\n",
    "        for i in range(4):\n",
    "            net_margin_mean = net_margin_mean + float(table[0].iloc[:, [3]].values[i][0][:-1])\n",
    "        net_margin_mean = round(net_margin_mean / 4, 2)\n",
    "    except:\n",
    "        net_margin_mean = 0\n",
    "    dataset.loc[j, 'net_margin_mean'] = net_margin_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем фундаментальные показатели компаний\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fb02a814cf4ee684fc51addd08f32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "jobs_count = multiprocessing.cpu_count()\n",
    "\n",
    "print ('Собираем фундаментальные показатели компаний')\n",
    "\n",
    "with parallel_backend('threading', n_jobs = jobs_count):\n",
    "    Parallel()(delayed(parsing_web_data)(m) for m in tqdm_notebook(range(len(tickers_only))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_excel('all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  107 of 107 completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44af239334bc41fa87d437575e9a93c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# отбираем стабильно растущие с 2016 года\n",
    "\n",
    "dataset_cut = copy.deepcopy(dataset)\n",
    "dataset_cut.loc[dataset_cut['ROE'] < 0.12, 'ROE'] = None\n",
    "dataset_cut.loc[dataset_cut['marketCap'] < 10000000000, 'marketCap'] = None\n",
    "dataset_cut.loc[dataset_cut['growth'] < 10, 'growth'] = None\n",
    "dataset_cut.loc[dataset_cut['growth'] > 40, 'growth'] = 40\n",
    "dataset_cut.loc[dataset_cut['determination'] < 0.5, 'determination'] = None\n",
    "dataset_cut.loc[dataset_cut['net_margin_mean'] < 5, 'net_margin_mean'] = None\n",
    "dataset_cut.loc[dataset_cut['net_margin_mean'] > 35, 'net_margin_mean'] = 35\n",
    "\n",
    "dataset_cut = dataset_cut.dropna().reset_index(drop=True)\n",
    "\n",
    "minimum = np.min(dataset_cut.marketCap.values)\n",
    "maximum = np.max(dataset_cut.marketCap.values)\n",
    "dataset_cut['marketCap_score'] = dataset_cut['marketCap'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "minimum = np.min(dataset_cut.growth.values)\n",
    "maximum = np.max(dataset_cut.growth.values)\n",
    "dataset_cut['growth_score'] = dataset_cut['growth'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "minimum = np.min(dataset_cut.determination.values)\n",
    "maximum = np.max(dataset_cut.determination.values)\n",
    "dataset_cut['determination_score'] = dataset_cut['determination'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "minimum = np.min(dataset_cut.net_margin_mean.values)\n",
    "maximum = np.max(dataset_cut.net_margin_mean.values)\n",
    "dataset_cut['net_margin_mean_score'] = dataset_cut['net_margin_mean'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "dataset_cut['Score'] = dataset_cut[\"marketCap_score\"] + dataset_cut[\"growth_score\"] +  dataset_cut[\"determination_score\"] +  dataset_cut[\"net_margin_mean_score\"]\n",
    "\n",
    "yf.pdr_override()\n",
    "data = web.get_data_yahoo(list(dataset_cut['s_RTS_code'].values), start=str((date.today() - timedelta(days=360)).strftime(\"%Y-%m-%d\")), end=str(date.today().strftime(\"%Y-%m-%d\")), auto_adjust = True)\n",
    "\n",
    "for k in tqdm_notebook(range(len(dataset_cut['s_RTS_code'].values))):\n",
    "    dens = np.histogram(data['Close'][data['Close'].columns[k]].values[~np.isnan(data['Close'][data['Close'].columns[k]].values)])[0]\n",
    "    prices = np.histogram(data['Close'][data['Close'].columns[k]].values[~np.isnan(data['Close'][data['Close'].columns[k]].values)])[1]\n",
    "    for p in range(len(dens)):\n",
    "        if dens[len(dens) - 2 - p] > dens[len(dens) - 1 - p] and dens[len(dens) - 2 - p] > dens[len(dens) - 3 - p] and dens[len(dens) - 2 - p] > 1.2*dens[-2-level]:\n",
    "            level = p\n",
    "            break\n",
    "\n",
    "    nice_price = prices[6]\n",
    "    price_now = data['Close'][data['Close'].columns[k]].values[~np.isnan(data['Close'][data['Close'].columns[k]].values)][-1]\n",
    "    overprice = round(((price_now - nice_price) / nice_price) * 100, 2)\n",
    "\n",
    "    dataset_cut.loc[k, 'overprice'] = overprice\n",
    "\n",
    "dataset_cut = dataset_cut.sort_values(by = 'Score', ascending = False).reset_index(drop=True)\n",
    "\n",
    "dataset_cut.to_excel('growth.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e998f039617f40fa9619479ec45592bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in tqdm_notebook(range(len(dataset_cut['s_RTS_code'].values))):\n",
    "    response = requests.get('https://finance.yahoo.com/quote/' + dataset_cut['s_RTS_code'][k] +'/analysis/', headers={'User-Agent': UserAgent().chrome})\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    string_soup = str(soup)\n",
    "\n",
    "    pos1 = string_soup.find('Next 5 Years (per annum)')\n",
    "    string_soup = string_soup[pos1:]\n",
    "    pos2 = string_soup.find('%')\n",
    "    string_soup = string_soup[(pos2-6):pos2]\n",
    "    pos3 = string_soup.find('>')\n",
    "    try:\n",
    "        future_growth = float(string_soup[pos3+1:])\n",
    "    except:\n",
    "        future_growth = 0\n",
    "    dataset_cut.loc[k, 'future_growth'] = future_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_cut[['marketCap_score', 'growth_score', 'determination_score', 'net_margin_mean_score']].values\n",
    "y = dataset_cut[['P/E']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "predictions = rf.predict(X)\n",
    "\n",
    "df_rf = pd.DataFrame({'Name': dataset_cut['s_RTS_code'].values,'Score': dataset_cut['Score'].values, 'Actual': y.ravel(), 'Predicted': predictions.ravel()})\n",
    "\n",
    "df_rf['overprice_ML'] = round(100*(df_rf['Actual'] - df_rf['Predicted'])/df_rf['Predicted'], 2)\n",
    "\n",
    "dataset_cut['overprice_ML'] = df_rf['overprice_ML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  107 of 107 completed\n"
     ]
    }
   ],
   "source": [
    "# найдём RSI для growth\n",
    "yf.pdr_override()\n",
    "data = web.get_data_yahoo(list(dataset_cut['s_RTS_code'].values), start=str((date.today() - timedelta(days=100)).strftime(\"%Y-%m-%d\")), end=str(date.today().strftime(\"%Y-%m-%d\")), auto_adjust = True)\n",
    "\n",
    "RSI_list = list()\n",
    "\n",
    "for ticker in dataset_cut['s_RTS_code'].values:\n",
    "    change_list = list()\n",
    "    AvgU = 0\n",
    "    AvgD = 0\n",
    "    for i in range(16):\n",
    "        change = (data['Close'][ticker][len(data['Close'])-i-1] - data['Close'][ticker][len(data['Close'])-2-i])/data['Close'][ticker][len(data['Close'])-2-i]\n",
    "        change_list.append(change)\n",
    "\n",
    "        \n",
    "        if change > 0:\n",
    "            AvgU = AvgU + change_list[i]\n",
    "        if change < 0:\n",
    "            AvgD = AvgD - change_list[i]\n",
    "    RS = AvgU / AvgD\n",
    "    RSI = 100 - 100/(1 + RS)\n",
    "    RSI_list.append(RSI)\n",
    "    \n",
    "dataset_cut['RSI'] = RSI_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_boost_data(j):\n",
    "\n",
    "    try:\n",
    "        tickerSymbol = tickers_only[j]\n",
    "        tickerData = yf.Ticker(tickerSymbol)\n",
    "        ticker_info = tickerData.info\n",
    "        marketCap = ticker_info['marketCap']\n",
    "        P_S = ticker_info['priceToSalesTrailing12Months']\n",
    "        price = ticker_info['currentPrice']\n",
    "    except:\n",
    "        marketCap = 0\n",
    "        P_S = 0\n",
    "        price = 0\n",
    "    dataset_new.loc[j, 'marketCap'] = marketCap\n",
    "    dataset_new.loc[j, 'price'] = price\n",
    "    dataset_new.loc[j, 'P/S'] = P_S\n",
    "    \n",
    "    try:\n",
    "        table=pd.read_html('https://www.macrotrends.net/stocks/charts/' + tickers_only[j] + '/' + tickers_only[j] + '/gross-profit')\n",
    "        rg_table = table[1]\n",
    "        rg_table = rg_table.iloc[:, 1].values\n",
    "        rg_table = filter(lambda v: v==v, rg_table)\n",
    "        rg_table = [s.replace('$', '') for s in rg_table]\n",
    "        rg_table = [s.replace(',', '') for s in rg_table]\n",
    "        x = np.asarray(rg_table, dtype=np.float64)\n",
    "        x_rev = np.flip(x)\n",
    "\n",
    "        ttm_list = list()\n",
    "        growth_list = list()\n",
    "\n",
    "        if len(x_rev) <= 4:\n",
    "            rg_table = table[0]\n",
    "            rg_table = rg_table.iloc[:, 1].values\n",
    "            rg_table = filter(lambda v: v==v, rg_table)\n",
    "            rg_table = [s.replace('$', '') for s in rg_table]\n",
    "            rg_table = [s.replace(',', '') for s in rg_table]\n",
    "            x = np.asarray(rg_table, dtype=np.float64)\n",
    "            x_rev = np.flip(x)\n",
    "            for i in range(len(x_rev) - 1):\n",
    "                growth_list.append((x_rev[i+1] - x_rev[i]) / x_rev[i])\n",
    "\n",
    "            rev_growth = np.median(growth_list)\n",
    "\n",
    "            if np.min(growth_list) < 0.1:\n",
    "                rev_growth = 0\n",
    "\n",
    "        else:\n",
    "            for i in range(len(x_rev)-3):\n",
    "                ttm = x_rev[i] + x_rev[i+1] + x_rev[i+2] + x_rev[i+3]\n",
    "                ttm_list.append(ttm)\n",
    "\n",
    "\n",
    "            for i in range(len(x_rev)-6):\n",
    "                growth_list.append((ttm_list[i+3] - ttm_list[i])/ttm_list[i])\n",
    "\n",
    "            rev_growth = np.median(growth_list[-8:])\n",
    "\n",
    "            if np.min(growth_list[-8:]) < 0.15:\n",
    "                rev_growth = 0\n",
    "        \n",
    "    except:\n",
    "        rev_growth = 0\n",
    "        \n",
    "    dataset_new.loc[j, 'rev_growth'] = rev_growth\n",
    "    \n",
    "    \n",
    "      \n",
    "    try:\n",
    "        table=pd.read_html('https://www.macrotrends.net/stocks/charts/' + tickers_only[j] + '/' + tickers_only[j] + '/net-income')\n",
    "        rg_table = table[1]\n",
    "        rg_table = rg_table.iloc[:, 1].values\n",
    "        rg_table = filter(lambda v: v==v, rg_table)\n",
    "        rg_table = [s.replace('$', '') for s in rg_table]\n",
    "        rg_table = [s.replace(',', '') for s in rg_table]\n",
    "        x = np.asarray(rg_table, dtype=np.float64)\n",
    "        x_rev = np.flip(x)\n",
    "        x_rev = x_rev[-12:]\n",
    "\n",
    "        ttm_list = list()\n",
    "        for i in range(len(x_rev)-3):\n",
    "            ttm = x_rev[i] + x_rev[i+1] + x_rev[i+2] + x_rev[i+3]\n",
    "            ttm_list.append(ttm)\n",
    "\n",
    "        X = np.linspace(1, len(ttm_list), num=len(ttm_list))\n",
    "        X = X.reshape(-1, 1)\n",
    "        \n",
    "        reg = LinearRegression().fit(X, ttm_list)\n",
    "        growth = round((reg.predict(X)[-1] - reg.predict(X)[0]) / abs(reg.predict(X)[0]), 2)\n",
    "         \n",
    "    except:\n",
    "        growth = 0\n",
    "        \n",
    "    dataset_new.loc[j, 'eps_growth'] = growth\n",
    "   \n",
    "    try:\n",
    "        table=pd.read_html('https://www.macrotrends.net/stocks/charts/' + tickers_only[j] + '/' + tickers_only[j] + '/net-profit-margin')\n",
    "        net_margin_mean = 0\n",
    "        for i in range(4):\n",
    "            net_margin_mean = net_margin_mean + float(table[0].iloc[:, [3]].values[i][0][:-1])\n",
    "        net_margin_mean = round(net_margin_mean / 4, 2)\n",
    "    except:\n",
    "        net_margin_mean = 0\n",
    "    dataset_new.loc[j, 'net_margin_mean'] = net_margin_mean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем фундаментальные показатели компаний\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1370eb7cd04bbe91dda56bdce4303c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "jobs_count = multiprocessing.cpu_count()\n",
    "\n",
    "print ('Собираем фундаментальные показатели компаний')\n",
    "\n",
    "dataset_new = pd.read_csv('ListingSecurityList.csv', sep = ';')\n",
    "dataset_new = dataset_new[['s_RTS_code', 'e_full_name']]\n",
    "\n",
    "with parallel_backend('threading', n_jobs = jobs_count):\n",
    "    Parallel()(delayed(parsing_boost_data)(m) for m in tqdm_notebook(range(len(tickers_only))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new.to_excel('all_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  125 of 125 completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198e740f38334bdf8033dc822f3508fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_new_cut = copy.deepcopy(dataset_new)\n",
    "dataset_new_cut.loc[dataset_new_cut['rev_growth'] <= 0, 'rev_growth'] = None\n",
    "dataset_new_cut.loc[dataset_new_cut['rev_growth'] > 1, 'rev_growth'] = 1\n",
    "dataset_new_cut.loc[dataset_new_cut['eps_growth'] < 0, 'eps_growth'] = 0\n",
    "dataset_new_cut.loc[dataset_new_cut['eps_growth'] > 2, 'eps_growth'] = 2\n",
    "dataset_new_cut.loc[dataset_new_cut['net_margin_mean'] > 15, 'net_margin_mean'] = 15\n",
    "dataset_new_cut.loc[dataset_new_cut['net_margin_mean'] < -10, 'net_margin_mean'] = -10\n",
    "\n",
    "dataset_new_cut = dataset_new_cut.dropna().reset_index(drop=True)\n",
    "\n",
    "minimum = np.min(dataset_new_cut.rev_growth.values)\n",
    "maximum = np.max(dataset_new_cut.rev_growth.values)\n",
    "dataset_new_cut['rev_growth_score'] = dataset_new_cut['rev_growth'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "minimum = np.min(dataset_new_cut.eps_growth.values)\n",
    "maximum = np.max(dataset_new_cut.eps_growth.values)\n",
    "dataset_new_cut['eps_growth_score'] = dataset_new_cut['eps_growth'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "minimum = np.min(dataset_new_cut.net_margin_mean.values)\n",
    "maximum = np.max(dataset_new_cut.net_margin_mean.values)\n",
    "dataset_new_cut['net_margin_score'] = dataset_new_cut['net_margin_mean'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "dataset_new_cut['Score'] = 1.5 * dataset_new_cut['rev_growth_score'] + 1.5 * dataset_new_cut['eps_growth_score'] + dataset_new_cut['net_margin_score']\n",
    "\n",
    "yf.pdr_override()\n",
    "data = web.get_data_yahoo(list(dataset_new_cut['s_RTS_code'].values), start=str((date.today() - timedelta(days=120)).strftime(\"%Y-%m-%d\")), end=str(date.today().strftime(\"%Y-%m-%d\")), auto_adjust = True)\n",
    "sale_cluster_list = list()\n",
    "for k in tqdm_notebook(range(len(dataset_new_cut['s_RTS_code'].values))):\n",
    "    try:\n",
    "        nice_price = np.histogram(data['Close'][data['Close'].columns[k]].values)[1][6]\n",
    "        price_now = data['Close'][data['Close'].columns[k]].values[-1]\n",
    "        overprice = round(((price_now - nice_price) / nice_price) * 100, 2)\n",
    "        \n",
    "    except:\n",
    "        overprice = -100\n",
    "    dataset_new_cut.loc[k, 'overprice'] = overprice\n",
    "\n",
    "    \n",
    "dataset_new_cut = dataset_new_cut.sort_values(by = 'Score', ascending = False).reset_index(drop=True)\n",
    "\n",
    "dataset_new_cut.to_excel('boost.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441ccbbd041b4ede890c09a44dc715f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in tqdm_notebook(range(len(dataset_new_cut['s_RTS_code'].values))):\n",
    "    response = requests.get('https://finance.yahoo.com/quote/' + dataset_new_cut['s_RTS_code'][k] +'/analysis/', headers={'User-Agent': UserAgent().chrome})\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    string_soup = str(soup)\n",
    "\n",
    "    pos1 = string_soup.find('Next 5 Years (per annum)')\n",
    "    string_soup = string_soup[pos1:]\n",
    "    pos2 = string_soup.find('%')\n",
    "    string_soup = string_soup[(pos2-6):pos2]\n",
    "    pos3 = string_soup.find('>')\n",
    "    try:\n",
    "        future_growth = float(string_soup[pos3+1:])\n",
    "    except:\n",
    "        try:\n",
    "            string_soup = str(soup)\n",
    "            pos1 = string_soup.find('Next Year')\n",
    "            string_soup = string_soup[pos1+1:]\n",
    "            pos1 = string_soup.find('Next Year')\n",
    "            string_soup = string_soup[pos1+1:]\n",
    "            pos1 = string_soup.find('Next Year')\n",
    "            string_soup = string_soup[pos1+1:]\n",
    "            pos1 = string_soup.find('Next Year')\n",
    "            string_soup = string_soup[pos1+1:]\n",
    "            pos1 = string_soup.find('Next Year')\n",
    "            string_soup = string_soup[pos1+1:]\n",
    "            pos2 = string_soup.find('%')\n",
    "            string_soup = string_soup[(pos2-6):pos2]\n",
    "            pos3 = string_soup.find('>')\n",
    "            future_growth = float(string_soup[pos3+1:])\n",
    "\n",
    "        except:\n",
    "            future_growth = 0\n",
    "    dataset_new_cut.loc[k, 'future_growth'] = future_growth\n",
    "    \n",
    "minimum = np.min(dataset_new_cut.future_growth.values)\n",
    "maximum = np.max(dataset_new_cut.future_growth.values)\n",
    "dataset_new_cut['future_growth_score'] = dataset_new_cut['future_growth'].map(lambda x: (x - minimum)/(maximum - minimum))\n",
    "\n",
    "dataset_new_cut['Score'] = 1.5 * dataset_new_cut['rev_growth_score'] + 1.5 * dataset_new_cut['eps_growth_score'] + 1.5 * dataset_new_cut['future_growth_score'] + dataset_new_cut['net_margin_score']\n",
    "dataset_new_cut = dataset_new_cut.sort_values(by = 'Score', ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_new_cut[['rev_growth', 'future_growth']].values\n",
    "y = dataset_new_cut[['P/S']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "predictions = rf.predict(X)\n",
    "\n",
    "df_rf = pd.DataFrame({'Name': dataset_new_cut['s_RTS_code'].values,'Score': dataset_new_cut['Score'].values, 'Actual': y.ravel(), 'Predicted': predictions.ravel()})\n",
    "\n",
    "df_rf['overprice_ML'] = 100*(df_rf['Actual'] - df_rf['Predicted'])/df_rf['Predicted']\n",
    "\n",
    "dataset_new_cut['overprice_ML'] = df_rf['overprice_ML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  125 of 125 completed\n"
     ]
    }
   ],
   "source": [
    "# найдём RSI для boost\n",
    "yf.pdr_override()\n",
    "data = web.get_data_yahoo(list(dataset_new_cut['s_RTS_code'].values), start=str((date.today() - timedelta(days=50)).strftime(\"%Y-%m-%d\")), end=str(date.today().strftime(\"%Y-%m-%d\")), auto_adjust = True)\n",
    "\n",
    "RSI_list = list()\n",
    "\n",
    "for ticker in dataset_new_cut['s_RTS_code'].values:\n",
    "    change_list = list()\n",
    "    AvgU = 0\n",
    "    AvgD = 0\n",
    "    for i in range(15):\n",
    "        change = (data['Close'][ticker][len(data['Close'])-i-1] - data['Close'][ticker][len(data['Close'])-i-2])/data['Close'][ticker][len(data['Close'])-i-2]\n",
    "        change_list.append(change)\n",
    "\n",
    "        \n",
    "        if change > 0:\n",
    "            AvgU = AvgU + change_list[i]\n",
    "        if change < 0:\n",
    "            AvgD = AvgD - change_list[i]\n",
    "    RS = AvgU / AvgD\n",
    "    RSI = 100 - 100/(1 + RS)\n",
    "    RSI_list.append(RSI)\n",
    "    \n",
    "dataset_new_cut['RSI'] = RSI_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new_cut.to_excel('boost.xlsx')\n",
    "dataset_cut.to_excel('growth.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
